{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFD Input Generation Dashboard\n",
    "\n",
    "A lightweight workflow dashboard and controlled batch runner for `generateInputs.py`.\n",
    "\n",
    "This notebook orchestrates the dataset-preparation pipeline:\n",
    "1. Download DEM + roughness tiles for each coordinate in `coords.csv`\n",
    "2. Generate terrain meshes and ABL boundary conditions for each wind direction\n",
    "3. Produce `pipeline_metadata.json` per rotation (one per OpenFOAM case input)\n",
    "\n",
    "**Resume-safe:** Close and reopen at any time.  \n",
    "All decisions are derived from the filesystem: terrain folder existence and\n",
    "`pipeline_metadata.json` files inside each `rotatedTerrain_*_deg/` sub-directory.\n",
    "\n",
    "This notebook does **not** reimplement any pipeline logic — it only orchestrates\n",
    "by calling existing functions from `generateInputs.py` modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Edit these settings before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# ── Paths ────────────────────────────────────────────────────────────────────\n",
    "# Root of the CFD-dataset repository (directory containing this notebook)\n",
    "REPO_ROOT = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Path to the CSV file listing all (lat, lon) coordinates to process\n",
    "CSV_PATH = os.path.join(REPO_ROOT, \"coords.csv\")\n",
    "\n",
    "# Root folder where terrain sub-directories will be created\n",
    "# Structure: DATA_DIR / terrain_{index}_{lat}_{lon} / rotatedTerrain_{dir}_deg /\n",
    "DATA_DIR = os.path.join(REPO_ROOT, \"Data\", \"downloads\")\n",
    "\n",
    "# terrain_config.yaml used by the mesh pipeline\n",
    "TERRAIN_CONFIG_PATH = os.path.join(REPO_ROOT, \"terrain_config.yaml\")\n",
    "\n",
    "# ── Batch settings ────────────────────────────────────────────────────────────\n",
    "# Number of terrain coordinates to process in one run\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# Number of wind directions to generate per terrain\n",
    "# Total OpenFOAM case inputs = BATCH_SIZE * N_DIRECTIONS\n",
    "N_DIRECTIONS = 8\n",
    "\n",
    "# ── Download settings ────────────────────────────────────────────────────────\n",
    "# Tile side length in km for DEM / roughness download\n",
    "SIDE_LENGTH_KM = 50\n",
    "\n",
    "# Set to False to skip roughness map download (faster, but no z0 field)\n",
    "INCLUDE_ROUGHNESS = True\n",
    "\n",
    "# ── Submodule path setup ──────────────────────────────────────────────────────\n",
    "# Add submodule dirs to sys.path so their packages can be imported\n",
    "for _submod in [\"terrain_following_mesh_generator\", \"ABL_BC_generator\"]:\n",
    "    _p = os.path.join(REPO_ROOT, _submod)\n",
    "    if _p not in sys.path:\n",
    "        sys.path.insert(0, _p)\n",
    "\n",
    "print(f\"REPO_ROOT          : {REPO_ROOT}\")\n",
    "print(f\"CSV_PATH           : {CSV_PATH}\")\n",
    "print(f\"DATA_DIR           : {DATA_DIR}\")\n",
    "print(f\"TERRAIN_CONFIG     : {TERRAIN_CONFIG_PATH}\")\n",
    "print(f\"BATCH_SIZE         : {BATCH_SIZE}\")\n",
    "print(f\"N_DIRECTIONS       : {N_DIRECTIONS}\")\n",
    "print(f\"Total inputs/batch : {BATCH_SIZE * N_DIRECTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ── fetchData (always available in this repo) ─────────────────────────────────\n",
    "from fetchData.csv_utils import load_coordinates_from_csv\n",
    "from fetchData.parameter_generation import generate_directions\n",
    "from fetchData import download_raster_data, create_output_dir, DownloadConfig\n",
    "from fetchData.download_raster import format_coord\n",
    "\n",
    "print(\"✓ fetchData imported\")\n",
    "\n",
    "# ── terrain_following_mesh_generator (submodule) ──────────────────────────────\n",
    "try:\n",
    "    from terrain_following_mesh_generator import terrain_mesh as tm\n",
    "    _MESH_OK = True\n",
    "    print(\"✓ terrain_following_mesh_generator imported\")\n",
    "except ImportError as _e:\n",
    "    _MESH_OK = False\n",
    "    print(f\"✗ terrain_following_mesh_generator not available: {_e}\")\n",
    "    print(\"  Run: git submodule update --init --recursive\")\n",
    "\n",
    "# ── ABL_BC_generator (submodule) ──────────────────────────────────────────────\n",
    "try:\n",
    "    from ABL_BC_generator.generateBCs import generate_inlet_data_workflow, ABLConfig\n",
    "    _ABL_OK = True\n",
    "    print(\"✓ ABL_BC_generator imported\")\n",
    "except ImportError as _e:\n",
    "    _ABL_OK = False\n",
    "    print(f\"✗ ABL_BC_generator not available: {_e}\")\n",
    "    print(\"  Run: git submodule update --init --recursive\")\n",
    "\n",
    "_PIPELINE_AVAILABLE = _MESH_OK and _ABL_OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Status Scanner\n",
    "\n",
    "Reads `coords.csv` and checks the filesystem to determine the generation state\n",
    "of every coordinate.  \n",
    "**Re-run this cell at any time to refresh the view.**\n",
    "\n",
    "State definitions:\n",
    "| status | meaning |\n",
    "|---|---|\n",
    "| `not_started` | terrain folder does not exist |\n",
    "| `partial` | terrain folder exists, but fewer than `N_DIRECTIONS` rotation metadata files found |\n",
    "| `complete` | `≥ N_DIRECTIONS` rotation metadata files found |\n",
    "| `failed` | terrain folder exists but contains **zero** rotation metadata files |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _terrain_folder_path(lat: float, lon: float, index: int, data_dir: str) -> Path:\n",
    "    \"\"\"Return the expected terrain folder path for a coordinate.\"\"\"\n",
    "    lat_str = format_coord(lat, is_lat=True, precision=3)\n",
    "    lon_str = format_coord(lon, is_lat=False, precision=3)\n",
    "    folder_name = f\"terrain_{(index + 1):04d}_{lat_str}_{lon_str}\"\n",
    "    return Path(data_dir) / folder_name\n",
    "\n",
    "\n",
    "def _count_completed_rotations(terrain_path: Path) -> tuple[int, list[int]]:\n",
    "    \"\"\"\n",
    "    Count rotation sub-directories that have a `pipeline_metadata.json`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (count, directions)\n",
    "        count      : number of completed rotations\n",
    "        directions : sorted list of completed direction angles\n",
    "    \"\"\"\n",
    "    done_dirs = sorted(terrain_path.glob(\"rotatedTerrain_*_deg\"))\n",
    "    completed = []\n",
    "    for d in done_dirs:\n",
    "        if (d / \"pipeline_metadata.json\").exists():\n",
    "            # extract the degree value from the folder name, e.g. rotatedTerrain_045_deg -> 45\n",
    "            try:\n",
    "                deg = int(d.name.split(\"_\")[1])\n",
    "                completed.append(deg)\n",
    "            except (IndexError, ValueError):\n",
    "                pass\n",
    "    return len(completed), completed\n",
    "\n",
    "\n",
    "def scan_generation_status(csv_path: str, data_dir: str, n_directions: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scan the filesystem against `coords.csv` and return a status DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path    : path to coords.csv\n",
    "    data_dir    : root directory for terrain sub-folders\n",
    "    n_directions: target number of wind directions per terrain\n",
    "    \"\"\"\n",
    "    coordinates = load_coordinates_from_csv(csv_path, verbose=False)\n",
    "    records = []\n",
    "\n",
    "    for idx, (lat, lon) in enumerate(coordinates):\n",
    "        terrain_path = _terrain_folder_path(lat, lon, idx, data_dir)\n",
    "        exists = terrain_path.exists()\n",
    "\n",
    "        n_done, done_dirs = (0, []) if not exists else _count_completed_rotations(terrain_path)\n",
    "\n",
    "        if not exists:\n",
    "            status = \"not_started\"\n",
    "        elif n_done == 0:\n",
    "            status = \"failed\"\n",
    "        elif n_done < n_directions:\n",
    "            status = \"partial\"\n",
    "        else:\n",
    "            status = \"complete\"\n",
    "\n",
    "        records.append({\n",
    "            \"index\"          : idx,\n",
    "            \"lat\"            : lat,\n",
    "            \"lon\"            : lon,\n",
    "            \"terrain_folder\" : terrain_path.name,\n",
    "            \"folder_exists\"  : exists,\n",
    "            \"n_rotations_done\": n_done,\n",
    "            \"target_rotations\": n_directions,\n",
    "            \"status\"         : status,\n",
    "            \"done_directions\" : done_dirs,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# ── Run the scan ──────────────────────────────────────────────────────────────\n",
    "df_status = scan_generation_status(CSV_PATH, DATA_DIR, N_DIRECTIONS)\n",
    "print(f\"Scanned {len(df_status)} coordinate(s) at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary Dashboard\n",
    "\n",
    "Overall progress, per-status counts, and a per-terrain breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_ORDER = [\"not_started\", \"partial\", \"failed\", \"complete\"]\n",
    "STATUS_ICONS = {\"not_started\": \"○\", \"partial\": \"◑\", \"failed\": \"✗\", \"complete\": \"★\"}\n",
    "\n",
    "total_coords   = len(df_status)\n",
    "total_expected = total_coords * N_DIRECTIONS\n",
    "total_done     = int(df_status[\"n_rotations_done\"].sum())\n",
    "\n",
    "print(f\"{'='*55}\")\n",
    "print(f\"  CFD INPUT GENERATION STATUS\")\n",
    "print(f\"  {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"{'='*55}\")\n",
    "print(f\"  Total coordinates        : {total_coords}\")\n",
    "print(f\"  Target directions/terrain: {N_DIRECTIONS}\")\n",
    "print(f\"  Total inputs expected    : {total_expected}\")\n",
    "print(f\"  Total inputs generated   : {total_done}\")\n",
    "print(f\"  Progress                 : {total_done}/{total_expected}\",\n",
    "      f\"({100*total_done/total_expected:.1f}%)\" if total_expected > 0 else \"\")\n",
    "print()\n",
    "\n",
    "counts = df_status[\"status\"].value_counts()\n",
    "for s in STATUS_ORDER:\n",
    "    n = counts.get(s, 0)\n",
    "    if n > 0:\n",
    "        print(f\"  {STATUS_ICONS[s]}  {s:<14} : {n}\")\n",
    "print(f\"{'='*55}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Per-status count table ────────────────────────────────────────────────────\n",
    "count_df = (\n",
    "    df_status[\"status\"]\n",
    "    .value_counts()\n",
    "    .reindex(STATUS_ORDER)\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    "    .reset_index()\n",
    ")\n",
    "count_df.columns = [\"status\", \"count\"]\n",
    "count_df = count_df[count_df[\"count\"] > 0]\n",
    "display(count_df.style.hide(axis=\"index\").set_caption(\"Terrains per generation status\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Full per-terrain table ────────────────────────────────────────────────────\n",
    "display_cols = [\"index\", \"lat\", \"lon\", \"status\", \"n_rotations_done\", \"target_rotations\", \"terrain_folder\"]\n",
    "print(\"Per-terrain status table:\")\n",
    "display(df_status[display_cols].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Partial / failed cases ────────────────────────────────────────────────────\n",
    "df_needs_work = df_status[df_status[\"status\"].isin([\"not_started\", \"partial\", \"failed\"])]\n",
    "print(f\"Coordinates needing work: {len(df_needs_work)}\")\n",
    "if not df_needs_work.empty:\n",
    "    display(df_needs_work[[\"index\", \"lat\", \"lon\", \"status\", \"n_rotations_done\"]].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Controlled Batch Runner\n",
    "\n",
    "Finds the resume point (first incomplete coordinate) and processes the next\n",
    "`BATCH_SIZE` terrains, each with `N_DIRECTIONS` wind directions.\n",
    "\n",
    "- **Already-complete terrains** in the batch are silently skipped.\n",
    "- **Partially-complete terrains** skip any rotation that already has a\n",
    "  `pipeline_metadata.json`, generating only the missing ones.\n",
    "- **Not-started terrains** download DEM + roughness, then generate all directions.\n",
    "\n",
    "**Total new inputs this run ≤ `BATCH_SIZE` × `N_DIRECTIONS`**\n",
    "\n",
    "Re-run Cell 3 after the batch completes to refresh the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not _PIPELINE_AVAILABLE:\n",
    "    print(\"✗ One or more submodules are not available.\")\n",
    "    print(\"  Run: git submodule update --init --recursive\")\n",
    "else:\n",
    "    # ── Re-scan from disk to ensure we have fresh state ───────────────────────\n",
    "    df_fresh = scan_generation_status(CSV_PATH, DATA_DIR, N_DIRECTIONS)\n",
    "\n",
    "    # ── Find batch: first BATCH_SIZE incomplete terrains ─────────────────────\n",
    "    incomplete = df_fresh[df_fresh[\"status\"] != \"complete\"]\n",
    "    batch_df   = incomplete.head(BATCH_SIZE)\n",
    "\n",
    "    if batch_df.empty:\n",
    "        print(\"✓ All coordinates are complete — nothing to do.\")\n",
    "        print(\"  Add more coordinates to coords.csv and re-run.\")\n",
    "    else:\n",
    "        resume_idx = int(batch_df.iloc[0][\"index\"])\n",
    "        print(f\"Resuming from coordinate index {resume_idx}\")\n",
    "        print(f\"Batch: {len(batch_df)} terrain(s) × {N_DIRECTIONS} direction(s) = \"\n",
    "              f\"up to {len(batch_df) * N_DIRECTIONS} new inputs\\n\")\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            coord_idx = int(row[\"index\"])\n",
    "            lat, lon  = row[\"lat\"], row[\"lon\"]\n",
    "            status    = row[\"status\"]\n",
    "            done_dirs = row[\"done_directions\"]\n",
    "\n",
    "            print(f\"  [{coord_idx:04d}] lat={lat:.5f}, lon={lon:.5f}  status={status}\")\n",
    "\n",
    "            terrain_path = _terrain_folder_path(lat, lon, coord_idx, DATA_DIR)\n",
    "\n",
    "            # ── Step 1: Download DEM + roughness if terrain folder is missing ──\n",
    "            if status == \"not_started\":\n",
    "                download_config = DownloadConfig(\n",
    "                    side_length_km=SIDE_LENGTH_KM,\n",
    "                    include_roughness_map=INCLUDE_ROUGHNESS,\n",
    "                    save_raw_files=True,\n",
    "                    verbose=True,\n",
    "                    show_plots=False,\n",
    "                )\n",
    "                download_path = create_output_dir(lat, lon, coord_idx, DATA_DIR)\n",
    "                try:\n",
    "                    dem_file, roughness_file = download_raster_data(\n",
    "                        lat=lat, lon=lon, index=coord_idx,\n",
    "                        out_dir=download_path, config=download_config,\n",
    "                    )\n",
    "                    print(f\"    ✓ DEM downloaded: {dem_file}\")\n",
    "                    if roughness_file:\n",
    "                        print(f\"    ✓ Roughness downloaded: {roughness_file}\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"    ✗ Download failed: {exc}\")\n",
    "                    continue\n",
    "            else:\n",
    "                # Terrain folder exists — find the DEM and roughness files\n",
    "                dem_files  = sorted(terrain_path.glob(\"terrain_*.tif\"))\n",
    "                rmap_files = sorted(terrain_path.glob(\"roughness_*.tif\"))\n",
    "                # Prefer the UTM (non-raw) versions\n",
    "                dem_files  = [f for f in dem_files  if \"_raw\" not in f.name]\n",
    "                rmap_files = [f for f in rmap_files if \"_raw\" not in f.name]\n",
    "                if not dem_files:\n",
    "                    print(f\"    ✗ No DEM file found in {terrain_path} — skipping\")\n",
    "                    continue\n",
    "                dem_file      = str(dem_files[0])\n",
    "                roughness_file = str(rmap_files[0]) if rmap_files else None\n",
    "                print(f\"    ✓ Using existing DEM: {Path(dem_file).name}\")\n",
    "\n",
    "            # ── Step 2: Generate missing wind direction rotations ─────────────\n",
    "            mesh_config         = tm.load_config(TERRAIN_CONFIG_PATH)\n",
    "            inletBC_config      = ABLConfig()\n",
    "            terrain_mesh_pipeline = tm.TerrainMeshPipeline()\n",
    "\n",
    "            # Generate N_DIRECTIONS candidate directions, then skip any already done\n",
    "            candidate_directions = generate_directions(N_DIRECTIONS)\n",
    "            # Avoid re-running directions whose rotation folder already has metadata\n",
    "            new_directions = [d for d in candidate_directions if d not in done_dirs]\n",
    "            # If all candidates are already done, we still need to fill up to N_DIRECTIONS\n",
    "            still_needed = N_DIRECTIONS - len(done_dirs)\n",
    "            if still_needed <= 0:\n",
    "                print(f\"    ✓ Already has {len(done_dirs)} rotations — skipping\")\n",
    "                continue\n",
    "\n",
    "            directions_to_run = new_directions[:still_needed]\n",
    "            print(f\"    Generating {len(directions_to_run)} rotation(s): {directions_to_run}\")\n",
    "\n",
    "            for direction in directions_to_run:\n",
    "                subdir = f\"rotatedTerrain_{direction:03d}_deg\"\n",
    "                rotation_path = terrain_path / subdir\n",
    "\n",
    "                # Skip if metadata already exists (fine-grained resume)\n",
    "                if (rotation_path / \"pipeline_metadata.json\").exists():\n",
    "                    print(f\"      ↷ {subdir}: already done, skipping\")\n",
    "                    continue\n",
    "\n",
    "                rotation_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                try:\n",
    "                    mesh_config[\"terrain_config\"].rotation_deg = direction\n",
    "                    inletBC_config.flow_dir_deg                = direction\n",
    "\n",
    "                    terrain_mesh_pipeline.run(\n",
    "                        dem_path=dem_file,\n",
    "                        rmap_path=roughness_file,\n",
    "                        output_dir=str(rotation_path),\n",
    "                        **mesh_config,\n",
    "                    )\n",
    "                    generate_inlet_data_workflow(str(rotation_path), inletBC_config)\n",
    "                    print(f\"      ✓ {subdir}\")\n",
    "\n",
    "                except Exception as exc:\n",
    "                    print(f\"      ✗ {subdir}: {exc}\")\n",
    "\n",
    "        print(f\"\\nBatch complete. Re-run Cell 3 to refresh the dashboard.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
